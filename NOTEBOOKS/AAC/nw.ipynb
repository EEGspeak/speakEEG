{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NW AAC\n",
    "Next-word prediction for AAC board using Gensim and Word2Vec.\n",
    "\n",
    "Uses `contractions` to remove contractions from data.\n",
    "\n",
    "Uses Python 3.11.x and the libraries listed in the following imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# dealing with initial data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# word2vec implementation\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# data preprocessing\n",
    "import re\n",
    "import contractions\n",
    "\n",
    "# N-gram implementation dependency\n",
    "from collections import Counter\n",
    "\n",
    "# LSTM dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi, how are you doing?', \"i'm fine. how about yourself?\", \"i'm pretty good. thanks for asking.\", 'no problem. so how have you been?', \"i've been great. what about you?\"]\n",
      "3725 3725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hi, how are you doing?</td>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>i've been great. what about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>i've been great. what about you?</td>\n",
       "      <td>i've been good. i'm in school right now.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num                             question  \\\n",
       "0    0               hi, how are you doing?   \n",
       "1    1        i'm fine. how about yourself?   \n",
       "2    2  i'm pretty good. thanks for asking.   \n",
       "3    3    no problem. so how have you been?   \n",
       "4    4     i've been great. what about you?   \n",
       "\n",
       "                                     answer  \n",
       "0             i'm fine. how about yourself?  \n",
       "1       i'm pretty good. thanks for asking.  \n",
       "2         no problem. so how have you been?  \n",
       "3          i've been great. what about you?  \n",
       "4  i've been good. i'm in school right now.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data, convert to lists\n",
    "df = pd.read_csv(\"Conversation.csv\")\n",
    "\n",
    "qlist = df[\"question\"].tolist()\n",
    "alist = df[\"answer\"].tolist()\n",
    "print(qlist[:5])\n",
    "print(len(qlist), len(alist))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3725 3725\n",
      "['poodles bark a lot.', 'they sure do.', 'they bark at everything.', 'they never shut up.', 'why did you get a poodle?', \"it is my mom's dog.\", 'so she likes poodles.']\n",
      "['they sure do.', 'they bark at everything.', 'they never shut up.', 'why did you get a poodle?', \"it is my mom's dog.\", 'so she likes poodles.', 'she says they are good watchdogs.']\n",
      "['we have not been in a while.', 'we have not been in a month.', 'the last time we went, you almost drowned.', 'no, i did not.', 'then why did the lifeguard dive into the water?', 'i think he wanted to cool off.', 'he swam right up to you.']\n",
      "['we have not been in a month.', 'the last time we went, you almost drowned.', 'no, i did not.', 'then why did the lifeguard dive into the water?', 'i think he wanted to cool off.', 'he swam right up to you.', 'and then he turned right around.']\n"
     ]
    }
   ],
   "source": [
    "# remove contractions\n",
    "qlist = [contractions.fix(l) for l in qlist]\n",
    "alist = [contractions.fix(l) for l in alist]\n",
    "\n",
    "print(len(qlist), len(alist))\n",
    "\n",
    "print(qlist[765:772])\n",
    "print(alist[765:772])\n",
    "\n",
    "# does not remove possessives, though\n",
    "print(qlist[785:792])\n",
    "print(alist[785:792])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3725 3725\n",
      "['poodles bark a lot', 'they sure do', 'they bark at everything', 'they never shut up', 'why did you get a poodle', \"it is my mom's dog\", 'so she likes poodles']\n",
      "['they sure do', 'they bark at everything', 'they never shut up', 'why did you get a poodle', \"it is my mom's dog\", 'so she likes poodles', 'she says they are good watchdogs']\n",
      "['we have not been in a while', 'we have not been in a month', 'the last time we went you almost drowned', 'no i did not', 'then why did the lifeguard dive into the water', 'i think he wanted to cool off', 'he swam right up to you']\n",
      "['we have not been in a month', 'the last time we went you almost drowned', 'no i did not', 'then why did the lifeguard dive into the water', 'i think he wanted to cool off', 'he swam right up to you', 'and then he turned right around']\n"
     ]
    }
   ],
   "source": [
    "# remove punctuation, numbers, signs. except for remaining apostrophes\n",
    "qlist = [re.sub(r\"[^a-zA-Z\\s']\", \"\", l) for l in qlist]\n",
    "alist = [re.sub(r\"[^a-zA-Z\\s']\", \"\", l) for l in alist]\n",
    "\n",
    "print(len(qlist), len(alist))\n",
    "\n",
    "print(qlist[765:772])\n",
    "print(alist[765:772])\n",
    "\n",
    "print(qlist[785:792])\n",
    "print(alist[785:792])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['hi', 'how', 'are', 'you', 'doing'],\n",
       " ['i', 'am', 'fine', 'how', 'about', 'yourself'],\n",
       " ['i', 'am', 'pretty', 'good', 'thanks', 'for', 'asking'],\n",
       " ['no', 'problem', 'so', 'how', 'have', 'you', 'been'],\n",
       " ['i', 'have', 'been', 'great', 'what', 'about', 'you']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine to compatible sentences nested lists (each word becomes indiv element of parent list)\n",
    "sentences = list(map(lambda x : x.split(), qlist))\n",
    "sentences.extend(map(lambda x : x.split(), alist))\n",
    "\n",
    "print(len(sentences))\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003 300\n"
     ]
    }
   ],
   "source": [
    "# put into W2V model & save\n",
    "model = Word2Vec(sentences, vector_size=300, window=5, workers=4, epochs=10, min_count=5)\n",
    "model.save(\"conv.model\")\n",
    "\n",
    "pretrained_weights = model.wv.vectors\n",
    "vocab_size, embedding_size = pretrained_weights.shape\n",
    "print(vocab_size, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average context's embed vectors and find most similar vector for next word\n",
    "class WordPredictor:\n",
    "    def __init__(self, sentences: list[list[str]], method: str = \"word2vec\", max_ngram: int = 5):\n",
    "        \"\"\"\n",
    "        Initializes the predictor with training sentences\n",
    "\n",
    "        Args:\n",
    "            sentences: List of lists, inevitably loaded to W2V model\n",
    "            method: Prediction model specification (\"word2vec\", \"ngram\", or \"lstm\")\n",
    "            max_ngram: Maximum n-gram lookback size\n",
    "        \n",
    "        Methods:\n",
    "            build_vocabulary: creates a word-to-index mapping from training sentences\n",
    "            build_ngram_models: constructs multiple N-gram models with different context windows\n",
    "            predict_next_word: predicts next word given current context\n",
    "            prepare_lstm_data: prepares training data for LSTM model\n",
    "            build_lstm_model: initializes and trains LSTM model\n",
    "            predict_lstm: predicts next word using trained LSTM model\n",
    "        \"\"\"\n",
    "        self.method = method\n",
    "        self.sentences = sentences\n",
    "        self.vocab = self.build_vocabulary()\n",
    "\n",
    "        if method == \"word2vec\":\n",
    "            self.model = Word2Vec(\n",
    "                sentences, vector_size=100, window=5, min_count=1, workers=4\n",
    "            )\n",
    "\n",
    "        elif method == \"lstm\": # TODO\n",
    "            self.prepare_lstm_data()\n",
    "            self.build_lstm_model()\n",
    "\n",
    "        else:\n",
    "            self.max_ngram = max_ngram\n",
    "            self.build_ngram_models()\n",
    "    \n",
    "    def build_vocabulary(self):\n",
    "        \"\"\" Build vocabulary from sentences \"\"\"\n",
    "\n",
    "        words = []\n",
    "        for sentence in sentences:\n",
    "            words.extend(sentence)\n",
    "\n",
    "        unique_words = set(words)\n",
    "\n",
    "        vocab = {word: idx for idx, word in enumerate(unique_words)}\n",
    "        \n",
    "        return vocab\n",
    "\n",
    "    def build_ngram_models(self):\n",
    "        \"\"\"\n",
    "        Build multiple N-gram models from the training sentences\n",
    "        Implements backoff in case phrase not found in training data\n",
    "        \"\"\"\n",
    "        self.ngram_models = {}\n",
    "\n",
    "        for n in range(self.max_ngram, 1, -1):\n",
    "            self.ngram_models[n] = {} # access each model using its context size\n",
    "\n",
    "            for sentence in self.sentences:\n",
    "                for i in range(len(sentence) - n + 1): # iterate through all context windows of length `n`\n",
    "                    prefix = tuple(sentence[i:i+n-1])\n",
    "                    next_word = sentence[i+n-1]\n",
    "                    if prefix not in self.ngram_models[n]:\n",
    "                        self.ngram_models[n][prefix] = Counter()\n",
    "                    self.ngram_models[n][prefix][next_word] += 1\n",
    "\n",
    "\n",
    "    def predict_next_word(self, context, top_n=5):\n",
    "        \"\"\"\n",
    "        Predict the next word given a context\n",
    "\n",
    "        Args:\n",
    "            context: List of words\n",
    "            top_n: # of predictions to return\n",
    "        \n",
    "        Returns:\n",
    "            List of (word, score) tuples\n",
    "        \"\"\"\n",
    "\n",
    "        if self.method == \"word2vec\":\n",
    "            context_vectors = [self.model.wv[word] for word in context]\n",
    "            avg_vector = np.mean(context_vectors, axis=0)\n",
    "\n",
    "            similar_words = self.model.wv.similar_by_vector(avg_vector, topn=top_n)\n",
    "\n",
    "            return similar_words\n",
    "\n",
    "        elif self.method == \"lstm\":\n",
    "            return self.predict_lstm(context, top_n) # TODO\n",
    "        \n",
    "        else: # method = N-gram w/ backoff\n",
    "            for n in range(self.max_ngram, 1, -1): # find the largest N-gram that works\n",
    "                if len(context) >= n - 1:\n",
    "                    prefix = tuple(context[-(n-1):])\n",
    "                    if prefix in self.ngram_models[n]:\n",
    "                        predictions = self.ngram_models[n][prefix].most_common(top_n)\n",
    "                        total = sum(self.ngram_models[n][prefix].values())\n",
    "                        return [(word, count / total) for word, count in predictions]\n",
    "            \n",
    "            # worst case just return most common words (unigram)\n",
    "            if 2 in self.ngram_models:\n",
    "                all_words = Counter()\n",
    "                for ngram_dict in self.ngram_models[2].values():\n",
    "                    all_words.update(ngram_dict)\n",
    "                total = sum(all_words.values())\n",
    "                return [(word, count / total) for word, count in all_words.most_common(top_n)]\n",
    "            \n",
    "            return [] # NULLGRAM (empty training dataset)\n",
    "    \n",
    "    def prepare_lstm_data(self): # TODO\n",
    "        \"\"\"\n",
    "        Prepare data for LSTM training\n",
    "        \"\"\"\n",
    "\n",
    "        self.word_to_idx = {word: idx for idx, word in enumerate(self.vocab)}\n",
    "        self.idx_to_word = {idx: word for word, idx in self.word_to_idx.items()}\n",
    "        self.vocab_size = len(self.vocab)\n",
    "\n",
    "        self.sequence_length = 5 # context window size\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "\n",
    "        for sentence in sentences:\n",
    "            indices = [self.word_to_idx[word] for word in sentence]\n",
    "            for i in range(len(indices) - self.sequence_length):\n",
    "                self.X.append(indices[i:i+self.sequence_length])\n",
    "                self.y.append(indices[i+self.sequence_length])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2417"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wp = WordPredictor(sentences, method=\"ngram\")\n",
    "wp.prepare_lstm_data()\n",
    "wp.vocab_size\n",
    "max(wp.word_to_idx.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('go', 0.22727272727272727), ('get', 0.13636363636363635), ('play', 0.09090909090909091), ('be', 0.06818181818181818), ('do', 0.045454545454545456)]\n",
      "he works\n",
      "he works only\n",
      "he works only in\n",
      "he works only in canada\n",
      "he works only in canada and\n"
     ]
    }
   ],
   "source": [
    "response = wp.predict_next_word([\"i\", \"feel\", \"like\", \"i\", \"want\", \"to\"])\n",
    "print(response)\n",
    "\n",
    "wl = [\"he\", \"works\"]\n",
    "\n",
    "for i in range(5):\n",
    "    print(\" \".join(wl))\n",
    "    n = wp.predict_next_word(wl)[0][0]\n",
    "    wl.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int = 100, hidden_dim: int = 128, num_layers: int = 2, dropout: float = 0.2):\n",
    "        \"\"\"\n",
    "        Initialize LSTM model for word prediction\n",
    "\n",
    "        Args:\n",
    "            vocab_size: Size of vocabulary\n",
    "            embedding_dim: Number of word embeddings\n",
    "            hidden_dim: Dimension of LSTM hidden layer\n",
    "            num_layers: Number of LSTM layers\n",
    "            dropout: Dropout probability\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        \"\"\"\n",
    "        embedding layer = vocab_size * embedding_dim\n",
    "        * Takes word indices as input (integers from 0 to `vocab_size` - 1)\n",
    "        * Converts words to vector of size `embedding_dim` to be learned during training\n",
    "        \"\"\"\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=(dropout if num_layers > 1 else 0)\n",
    "        )\n",
    "        \"\"\"\n",
    "        LSTM layer\n",
    "        * Input: sequence of embedding vectors\n",
    "        * Internal structure w/ three gates:\n",
    "          1. Forget gate: which info should be discarded from cell state\n",
    "          2. Input gate: which new information to store\n",
    "          3. Output gate: which cell state parts to output\n",
    "        \"\"\"\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout) # NOTE TO SELF: aardvark abandon 2-20 in word2vec -- figure out its terminology for easy remembrance and comparison\n",
    "\n",
    "        # output fully-connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        \"\"\"\n",
    "        Final hidden state from LSTM\n",
    "        * Projects to vocab_size dimensions, representing score for each word\n",
    "        \"\"\"\n",
    "\n",
    "        # initialize weights\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        \"\"\" Initialize model weights for better training \"\"\"\n",
    "        for name, param in self.named_parameters(): # iterator over parameters (weights & biases)\n",
    "            if \"weight\" in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif \"bias\" in name:\n",
    "                nn.init.zeros_(param)\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        \"\"\" Initialize hidden and cell states \"\"\"\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device))\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, hidden: tuple = None):\n",
    "        \"\"\"\n",
    "        Forward propagation\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, sequence_length)\n",
    "            hidden: Initial hidden state and cell state\n",
    "        \n",
    "        Returns:\n",
    "            output (torch.Tensor): Output tensor of shape (batch_size, vocab_size)\n",
    "            hidden: Final hidden state and cell state\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(batch_size, x.device)\n",
    "\n",
    "        # embed input: (batch_size, sequence_length) -> (batch_size, sequence_length, embedding)dim\n",
    "        embedded = self.embedding(x)\n",
    "\n",
    "        # forward pass\n",
    "        lstm_out, hidden = self.lstm(embedded, hidden)\n",
    "\n",
    "        # final output\n",
    "        output = lstm_out[:, -1, :] # take last timestep output\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('embedding.weight', Parameter containing:\n",
      "tensor([[-0.1854,  0.4026, -0.2340, -0.5288,  0.2336, -0.2268,  0.0333, -0.3519,\n",
      "          0.3073, -0.2234],\n",
      "        [-0.0628, -0.2259, -0.6137,  0.2654, -0.5434, -0.3132, -0.3817, -0.6215,\n",
      "          0.2641,  0.1673],\n",
      "        [ 0.5487,  0.3111, -0.6215, -0.1991,  0.1008,  0.0120,  0.0569,  0.2299,\n",
      "          0.1011,  0.0444],\n",
      "        [ 0.2415,  0.0025,  0.2758, -0.2346,  0.3705,  0.2363, -0.3213, -0.3495,\n",
      "          0.1680,  0.6126],\n",
      "        [ 0.1619, -0.4820,  0.1393,  0.1305, -0.1933, -0.6121,  0.2245, -0.1609,\n",
      "         -0.4278,  0.3423]], requires_grad=True)), ('lstm.weight_ih_l0', Parameter containing:\n",
      "tensor([[ 5.4835e-02,  5.2781e-02,  2.3842e-01, -2.3993e-01, -7.1917e-02,\n",
      "          1.6688e-01,  1.7426e-02, -1.1794e-03, -9.6998e-02, -2.5311e-01],\n",
      "        [ 2.0812e-01,  1.2616e-01,  3.0241e-02, -9.9474e-02,  2.3173e-01,\n",
      "         -2.1247e-01, -2.6304e-02, -3.5790e-02, -1.4537e-01,  1.9415e-01],\n",
      "        [-1.1740e-01,  1.2091e-01,  1.0645e-01, -1.6662e-01, -1.8489e-01,\n",
      "          1.7168e-01, -1.0759e-01, -1.1603e-01, -2.2307e-01,  2.1459e-01],\n",
      "        [-1.1949e-01,  1.3908e-01, -3.3262e-02, -6.5183e-02,  1.8276e-03,\n",
      "          2.1533e-01,  1.2620e-01,  1.7703e-01,  5.8699e-02, -1.9957e-01],\n",
      "        [-2.4113e-01, -2.0634e-01, -1.6239e-01,  5.3108e-02,  5.4333e-02,\n",
      "          1.9095e-01,  1.4257e-01,  3.9437e-02, -2.3307e-01, -1.5058e-01],\n",
      "        [-1.0618e-01, -7.2103e-02,  4.6561e-02, -9.5883e-03,  1.0175e-01,\n",
      "          1.4130e-01, -5.4145e-02, -5.1401e-02, -2.1758e-01, -7.1108e-02],\n",
      "        [-1.3791e-01, -2.3703e-01, -1.0584e-01, -1.1201e-01,  3.7495e-02,\n",
      "          1.2602e-01,  2.3316e-01,  2.5489e-01,  1.2289e-01, -9.4411e-02],\n",
      "        [ 3.8960e-02,  1.5163e-01, -1.4530e-01, -1.3839e-01,  1.6381e-01,\n",
      "         -1.4345e-01,  2.3580e-01,  1.1083e-01,  9.6905e-02,  8.3167e-02],\n",
      "        [-2.1561e-01,  2.2126e-01, -8.6230e-02,  2.5223e-01, -1.6710e-01,\n",
      "         -1.2319e-01,  7.7346e-02,  5.2947e-02,  7.3255e-02, -1.2853e-01],\n",
      "        [-4.7689e-02, -6.6926e-03,  2.2645e-01,  8.6650e-02, -3.3064e-02,\n",
      "          2.5426e-03,  6.7246e-02,  2.1232e-01,  1.5890e-01, -5.4784e-02],\n",
      "        [ 2.0419e-01,  1.3857e-01,  1.9400e-01,  1.3868e-01, -1.0216e-02,\n",
      "          1.2870e-01,  1.2625e-01, -2.4586e-01,  2.0007e-01,  1.5959e-01],\n",
      "        [-3.1867e-02,  1.6445e-01,  1.7073e-01, -5.2890e-02,  8.5922e-02,\n",
      "         -1.3130e-01,  8.7736e-02,  1.0427e-01, -6.9463e-02, -2.1776e-01],\n",
      "        [-1.4541e-01,  8.6503e-02, -1.8848e-02, -2.5287e-01, -1.9167e-01,\n",
      "         -7.8291e-02,  2.5021e-01,  3.8363e-02, -6.2301e-02,  2.4313e-01],\n",
      "        [ 9.3095e-02, -2.5817e-01,  1.1530e-01, -1.2091e-01,  1.8979e-01,\n",
      "          2.1495e-01, -1.6972e-01,  2.1184e-01, -9.4069e-02,  1.2467e-01],\n",
      "        [ 1.7294e-01, -1.7529e-01,  1.6137e-01,  3.4833e-02, -1.6602e-01,\n",
      "          1.5794e-01, -1.1802e-01,  2.3975e-02,  6.0030e-02, -1.7198e-03],\n",
      "        [ 9.6173e-02, -3.8320e-03, -2.4944e-01, -1.4733e-01,  2.5614e-01,\n",
      "         -6.2316e-02, -2.4196e-01,  1.0483e-01,  8.5546e-02, -9.3043e-02],\n",
      "        [ 2.1401e-02, -1.5418e-01, -1.9663e-01,  1.6827e-01,  1.9427e-01,\n",
      "          1.0917e-01, -1.4280e-01, -3.1693e-02,  1.6595e-01, -6.5827e-02],\n",
      "        [-2.0669e-01, -1.3334e-01, -2.5608e-02, -1.3156e-01, -1.2514e-01,\n",
      "         -2.2015e-01,  5.7221e-02, -4.6566e-02, -2.1430e-01,  2.0110e-01],\n",
      "        [ 2.3346e-01, -1.4094e-01,  1.9922e-01,  1.0206e-02,  3.7304e-02,\n",
      "         -6.8879e-02,  3.7014e-02,  1.8928e-01, -1.3687e-01,  6.2573e-02],\n",
      "        [-1.4267e-01,  2.2458e-01, -8.7040e-02,  6.0420e-02, -7.6605e-04,\n",
      "          3.8339e-02,  1.0869e-01, -5.0721e-02,  6.8054e-04,  1.6727e-01],\n",
      "        [-2.2440e-01,  9.2300e-02, -3.6315e-02,  1.8286e-01, -6.1278e-02,\n",
      "          2.4392e-01, -1.5313e-01,  1.9763e-01,  4.9697e-02,  1.6624e-01],\n",
      "        [ 1.5438e-01, -2.2058e-01, -1.8950e-02,  1.3561e-01,  1.8853e-02,\n",
      "         -1.8638e-01, -2.0047e-01,  2.3364e-01, -2.2091e-01, -1.2300e-01],\n",
      "        [ 1.2323e-01, -2.2936e-01, -1.6502e-01,  5.6854e-02, -2.4863e-01,\n",
      "          2.4669e-02, -1.0144e-01,  1.9748e-01,  9.7159e-02,  1.9329e-01],\n",
      "        [ 1.4411e-01, -1.2604e-01,  1.9617e-01, -2.1835e-01,  9.7111e-02,\n",
      "          2.4329e-01,  1.3664e-01, -1.6643e-02,  1.7560e-01, -2.5217e-01],\n",
      "        [-1.4599e-01, -5.9811e-02, -6.8526e-02,  2.2058e-01,  9.8109e-02,\n",
      "         -2.5650e-01,  1.2666e-01,  2.2948e-01, -1.7184e-01,  1.4533e-01],\n",
      "        [ 8.3117e-02,  2.2275e-01, -1.5405e-01,  1.3302e-01,  1.0829e-01,\n",
      "         -1.0089e-01, -1.2162e-01,  1.4796e-01,  1.5678e-01, -1.4336e-01],\n",
      "        [-1.1196e-02, -7.8181e-02, -1.6557e-01,  2.0761e-01, -1.6009e-01,\n",
      "          4.1217e-02, -1.6881e-01, -2.5039e-02,  1.9985e-01,  2.9420e-02],\n",
      "        [ 1.9099e-01, -2.1746e-01,  8.8742e-02, -3.2641e-02, -2.4183e-01,\n",
      "         -2.2761e-01, -9.5963e-02,  1.8703e-01, -6.7021e-02, -1.6906e-01],\n",
      "        [-2.4083e-01, -1.1713e-02,  4.3635e-02, -1.1880e-01,  2.5623e-01,\n",
      "         -1.5115e-02, -1.7854e-01, -9.7025e-02, -2.2713e-01, -2.3192e-01],\n",
      "        [-1.3113e-01,  1.2600e-01, -3.6810e-02, -2.1121e-01, -2.2231e-01,\n",
      "          3.0083e-02,  2.0872e-01,  2.2129e-01, -4.2161e-02,  1.8885e-01],\n",
      "        [ 1.6750e-01,  4.4097e-02,  1.6373e-01, -1.6487e-01, -1.7829e-02,\n",
      "          1.2564e-01,  7.0861e-02,  4.4596e-02, -6.6434e-03,  1.3710e-01],\n",
      "        [-1.2058e-01,  1.2716e-01,  1.0446e-01,  5.2178e-02,  3.2664e-02,\n",
      "          4.5576e-02,  1.3518e-01,  2.6187e-02,  9.3000e-02, -1.7165e-01],\n",
      "        [-1.8207e-01, -1.1450e-01,  1.1076e-01,  5.0013e-02,  6.2151e-02,\n",
      "          1.6542e-01, -1.0707e-01, -1.8607e-01, -5.7644e-02,  1.1371e-01],\n",
      "        [-3.0416e-02, -2.2049e-01,  1.5368e-01, -8.4757e-02,  1.3870e-01,\n",
      "         -1.0778e-01,  1.2893e-01,  1.5539e-01,  9.2964e-02,  3.7695e-02],\n",
      "        [ 6.1294e-02, -2.4436e-01,  1.0980e-01, -1.8426e-01, -2.4665e-01,\n",
      "         -5.1942e-03, -1.6966e-01, -5.5903e-02, -3.5650e-02,  1.2380e-01],\n",
      "        [ 8.0638e-02, -2.0741e-01, -3.1261e-02, -4.6754e-03, -2.3133e-02,\n",
      "          1.6443e-01, -1.7387e-01,  1.8956e-01, -1.6433e-01,  4.3607e-03],\n",
      "        [ 1.5881e-01, -6.2943e-02,  2.3896e-01,  2.0893e-01,  1.9806e-01,\n",
      "         -1.4609e-01,  9.0901e-02, -1.2145e-01, -1.8087e-01,  5.1429e-02],\n",
      "        [ 2.5578e-01,  1.7883e-01, -2.0404e-01, -5.0667e-03,  2.1141e-01,\n",
      "          1.9916e-01,  3.0186e-02, -2.0462e-01, -1.1746e-01, -1.8921e-01],\n",
      "        [ 1.4113e-01, -1.3024e-01, -6.4643e-02,  1.9920e-01, -1.1493e-01,\n",
      "          1.2355e-01,  1.9786e-01, -1.5185e-01, -1.1266e-02,  3.5777e-02],\n",
      "        [ 1.5165e-01,  1.2720e-02,  7.3246e-02,  9.2835e-02, -1.8630e-01,\n",
      "         -2.4276e-01,  1.0106e-01, -1.3558e-01,  6.9978e-03,  9.8845e-02],\n",
      "        [ 8.5031e-02,  8.4802e-02, -2.5113e-01,  2.5139e-01,  9.6349e-02,\n",
      "         -1.9783e-01,  1.5504e-01, -1.9227e-01, -2.0589e-01, -2.2361e-02],\n",
      "        [-2.2432e-01, -2.5172e-01,  1.3184e-01, -7.5990e-02,  2.1826e-01,\n",
      "          2.1192e-01,  6.8545e-02, -1.8166e-01,  6.7214e-02,  9.9562e-02],\n",
      "        [-1.6984e-01,  1.5161e-01, -1.3431e-01, -2.4437e-01,  1.6119e-01,\n",
      "         -1.3297e-01, -1.3014e-01, -6.7483e-02, -1.1372e-01, -4.8286e-02],\n",
      "        [-1.2150e-01, -4.8947e-02,  1.2724e-01, -1.6047e-01, -2.5178e-01,\n",
      "         -1.9174e-01, -1.1251e-01,  7.8560e-02,  4.9533e-02,  1.8589e-01],\n",
      "        [ 2.2237e-01,  2.1490e-01,  8.2199e-02,  1.8067e-01,  6.8842e-02,\n",
      "         -3.8050e-02,  1.3400e-01, -3.2521e-02,  1.3169e-01,  3.6776e-03],\n",
      "        [ 1.2070e-01,  8.3606e-02, -4.3791e-02,  7.9847e-02, -9.3674e-02,\n",
      "         -1.9236e-02, -7.9315e-02,  2.2168e-01,  5.5654e-02,  3.0128e-02],\n",
      "        [ 3.9647e-02,  6.8715e-02,  4.9119e-02, -1.8114e-01,  1.0156e-01,\n",
      "          2.1296e-01,  4.8274e-02, -1.7840e-01,  9.6613e-02, -1.9477e-01],\n",
      "        [ 2.4921e-01, -9.5725e-03, -1.0012e-01,  1.3715e-01, -2.5546e-01,\n",
      "         -8.1632e-02, -2.2780e-01, -1.2126e-01, -1.0752e-01,  2.4865e-02],\n",
      "        [-4.2108e-02, -1.9854e-01, -8.4792e-02, -9.5710e-02,  8.4557e-02,\n",
      "          2.3071e-02, -1.3418e-01, -1.4579e-01, -2.1222e-01, -2.3331e-01],\n",
      "        [-1.5239e-01,  4.7947e-02,  2.1028e-01, -2.0216e-01,  5.0463e-02,\n",
      "         -2.0526e-01, -5.9480e-02, -3.0570e-02,  8.7136e-02,  2.4389e-01],\n",
      "        [ 4.8487e-02, -1.9277e-01, -1.0706e-01,  3.1796e-02,  2.5767e-01,\n",
      "         -2.2521e-01,  5.5622e-02,  2.0169e-01, -3.9083e-02,  1.7171e-02],\n",
      "        [-3.3406e-02, -3.4604e-02, -6.8849e-02,  8.9604e-02,  1.5394e-01,\n",
      "         -2.0109e-02,  1.7140e-01,  1.1102e-01, -2.3267e-01,  1.8901e-02],\n",
      "        [ 5.3299e-02, -4.8002e-02,  4.2470e-02,  1.7938e-01, -2.2915e-01,\n",
      "          3.7943e-02,  9.7015e-02, -2.6376e-02,  2.3766e-02,  7.2089e-02],\n",
      "        [-1.3299e-01, -1.9954e-04,  4.0746e-02,  3.6339e-02,  2.3456e-01,\n",
      "         -5.7773e-02,  1.9313e-01, -2.1421e-01,  8.7498e-02, -2.9108e-02],\n",
      "        [ 4.6750e-02,  1.3378e-01,  1.1540e-01, -2.2820e-01, -9.2620e-02,\n",
      "          9.6494e-02, -1.6278e-01,  2.0187e-01,  1.4951e-02, -2.5329e-01],\n",
      "        [ 2.2611e-02, -1.9706e-01, -6.4620e-02,  1.7037e-01, -8.8327e-02,\n",
      "          1.0684e-01, -9.8702e-02,  6.1510e-04, -4.0277e-02, -6.7969e-02],\n",
      "        [ 2.2597e-01,  1.2766e-01,  1.6930e-01,  2.5734e-01,  1.2845e-01,\n",
      "         -1.2924e-01, -1.7031e-01,  2.2946e-01, -1.7241e-01, -1.3217e-01],\n",
      "        [-9.3743e-02,  7.4326e-02, -2.5118e-01,  4.6556e-02, -1.5289e-01,\n",
      "          2.0893e-01, -2.3782e-01, -1.1383e-01, -2.5756e-01,  2.3389e-01],\n",
      "        [ 2.1565e-01,  1.8440e-01,  2.3876e-01,  2.7257e-02, -6.4661e-03,\n",
      "          2.4374e-01, -1.9138e-01,  1.5557e-01,  2.5142e-01, -2.5543e-01],\n",
      "        [-4.1501e-03,  1.7020e-01, -5.0430e-02, -3.0455e-02, -4.9963e-02,\n",
      "         -1.5840e-01,  1.8988e-01, -2.0253e-01,  2.0541e-01, -1.9830e-01],\n",
      "        [-2.2501e-01,  2.0859e-01,  1.9359e-01, -2.9090e-02,  1.3059e-01,\n",
      "          1.2186e-01, -2.0583e-01,  2.1305e-01, -1.8829e-01, -1.7671e-01],\n",
      "        [-1.7643e-01, -2.0589e-01,  2.2597e-01,  1.7026e-01,  1.7896e-01,\n",
      "          1.8647e-01,  2.2172e-01,  4.0555e-03, -2.1372e-01,  1.8068e-01],\n",
      "        [ 2.3145e-01,  1.3897e-01,  2.0122e-01,  4.1852e-03, -1.7028e-01,\n",
      "          7.2815e-02,  1.2804e-01, -6.8326e-02,  3.1821e-02,  1.9624e-01],\n",
      "        [ 9.0554e-02, -9.2024e-02,  4.9594e-02,  2.4471e-01,  3.0875e-02,\n",
      "         -1.5045e-02, -2.4242e-01, -1.0006e-01, -3.2903e-02,  1.1240e-01],\n",
      "        [-1.2037e-01,  4.6642e-02,  8.9637e-02, -2.0745e-01,  1.9460e-01,\n",
      "         -2.4675e-01,  2.3401e-01, -1.2481e-01,  1.0895e-01,  1.8124e-01],\n",
      "        [ 2.4212e-01,  1.5264e-01,  1.8585e-01,  2.3113e-01, -1.4339e-01,\n",
      "         -1.8842e-01, -1.6320e-01, -2.1008e-01, -1.6702e-01, -1.2829e-02],\n",
      "        [-6.7004e-02, -8.0800e-02,  1.7685e-01,  2.0341e-01, -8.9705e-02,\n",
      "         -1.0265e-01,  1.3966e-01,  5.2585e-03, -2.1084e-01, -1.1986e-01],\n",
      "        [ 1.1060e-01, -5.8411e-02, -2.3443e-01,  1.8722e-01,  1.9803e-02,\n",
      "          1.4296e-01, -7.5894e-02, -2.4884e-01, -1.1294e-01, -9.6211e-02],\n",
      "        [-1.0721e-02, -9.8431e-02,  1.5091e-01,  2.0949e-01, -2.3170e-01,\n",
      "         -1.1980e-01,  2.3237e-02, -1.0064e-01, -2.2416e-01,  1.6107e-01],\n",
      "        [ 1.4160e-01, -1.4811e-01, -2.2932e-01, -7.1291e-03,  1.8060e-01,\n",
      "          1.0887e-01,  1.2324e-01,  1.1568e-01, -6.2229e-02, -2.0262e-01],\n",
      "        [-1.2473e-01, -2.9377e-02,  1.6371e-01,  3.2805e-03, -2.5014e-01,\n",
      "         -4.7652e-03, -6.6276e-02,  1.5038e-01,  1.7009e-02, -7.0303e-02],\n",
      "        [ 2.1856e-01, -3.4166e-03,  1.1078e-01,  4.7028e-02, -2.2181e-01,\n",
      "          2.2575e-01, -1.4971e-01, -2.0410e-01, -1.5239e-01, -1.8748e-02],\n",
      "        [-2.0771e-01, -1.5997e-01, -4.0929e-02,  1.5763e-02,  1.3549e-02,\n",
      "          1.7754e-01,  1.7070e-01,  1.2493e-01, -1.5993e-01,  3.2049e-02],\n",
      "        [-2.3200e-01, -2.1675e-01, -3.8103e-02,  1.0191e-01,  2.0398e-01,\n",
      "         -2.3532e-01, -2.1112e-01,  1.7284e-01,  2.0655e-01, -8.6037e-02],\n",
      "        [ 2.1591e-02,  9.4623e-03, -1.9178e-01, -2.0340e-01,  5.3118e-02,\n",
      "         -2.8451e-02, -3.2429e-02,  1.8370e-01,  1.5841e-01,  1.3445e-01],\n",
      "        [ 1.7523e-01,  3.3657e-02, -1.1961e-01,  9.5468e-02, -5.0378e-02,\n",
      "          2.1769e-01, -8.2356e-02, -6.8049e-02, -7.3101e-02, -2.3617e-01],\n",
      "        [ 8.9926e-02,  1.8923e-01,  1.9081e-01, -3.3241e-02, -1.4126e-01,\n",
      "         -1.5599e-01,  2.0764e-01,  2.4948e-01,  2.5175e-02,  7.1550e-02],\n",
      "        [-2.1618e-01,  6.8674e-02,  1.4436e-01, -6.7988e-02, -1.6133e-01,\n",
      "          1.4201e-01,  5.8349e-02, -5.3194e-02, -9.6102e-02,  7.4455e-02],\n",
      "        [ 7.7808e-02, -2.0592e-03, -8.7779e-02,  2.3112e-01, -2.0481e-01,\n",
      "         -2.4530e-01, -3.0258e-02,  2.4644e-01, -5.5857e-02,  1.2356e-01],\n",
      "        [ 3.9058e-02,  1.8478e-01, -1.0117e-01,  2.0516e-01, -1.6391e-01,\n",
      "         -1.4703e-01, -9.8877e-04,  6.2205e-03, -4.0025e-02,  4.8417e-03]],\n",
      "       requires_grad=True)), ('lstm.weight_hh_l0', Parameter containing:\n",
      "tensor([[-0.1481, -0.0212, -0.0577,  ..., -0.1396,  0.2355, -0.0379],\n",
      "        [-0.2144,  0.1229,  0.1853,  ...,  0.1898, -0.0135, -0.1335],\n",
      "        [-0.0525, -0.1292, -0.0739,  ...,  0.0444,  0.0774, -0.0969],\n",
      "        ...,\n",
      "        [ 0.0239,  0.2238, -0.0649,  ...,  0.0288, -0.0626, -0.0284],\n",
      "        [ 0.0268, -0.0942,  0.1811,  ...,  0.0233,  0.0119,  0.1187],\n",
      "        [ 0.0135,  0.0794,  0.0306,  ...,  0.0859,  0.0631, -0.1895]],\n",
      "       requires_grad=True)), ('lstm.bias_ih_l0', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)), ('lstm.bias_hh_l0', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)), ('lstm.weight_ih_l1', Parameter containing:\n",
      "tensor([[ 0.2415, -0.1813,  0.0302,  ..., -0.0017,  0.0456,  0.0653],\n",
      "        [-0.2194,  0.1010,  0.1464,  ..., -0.1395,  0.1582,  0.1711],\n",
      "        [-0.0078, -0.0752,  0.1442,  ...,  0.2255, -0.0794,  0.2270],\n",
      "        ...,\n",
      "        [ 0.0129,  0.0870, -0.1184,  ..., -0.1965,  0.0485,  0.0731],\n",
      "        [ 0.0135,  0.2090,  0.1133,  ...,  0.1017,  0.1515,  0.2443],\n",
      "        [-0.1498, -0.1417,  0.2065,  ...,  0.1313,  0.0750,  0.2031]],\n",
      "       requires_grad=True)), ('lstm.weight_hh_l1', Parameter containing:\n",
      "tensor([[-0.1613, -0.1337,  0.0439,  ...,  0.1327, -0.2442, -0.1858],\n",
      "        [-0.0453,  0.1649,  0.1056,  ...,  0.1133, -0.1517,  0.0789],\n",
      "        [ 0.2061,  0.1319, -0.1346,  ...,  0.1195, -0.0528, -0.0047],\n",
      "        ...,\n",
      "        [-0.0764,  0.0754, -0.0775,  ..., -0.1473, -0.1784, -0.1085],\n",
      "        [ 0.1497, -0.2118,  0.0648,  ...,  0.2161, -0.2060,  0.1691],\n",
      "        [ 0.0186,  0.2119, -0.1920,  ..., -0.2072, -0.0430,  0.2411]],\n",
      "       requires_grad=True)), ('lstm.bias_ih_l1', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)), ('lstm.bias_hh_l1', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)), ('fc.weight', Parameter containing:\n",
      "tensor([[-1.0326e-01, -1.2539e-01, -4.3177e-02, -4.6539e-01,  3.3110e-01,\n",
      "          2.0943e-01, -4.0410e-01, -7.4657e-02, -4.5438e-01,  4.6831e-01,\n",
      "          3.4134e-01, -8.0250e-02,  4.6834e-01,  2.2929e-01,  5.5076e-02,\n",
      "         -1.1312e-01,  2.6505e-01,  1.8792e-01,  4.2835e-01, -2.5921e-01],\n",
      "        [ 3.2242e-01,  1.4245e-01,  4.3005e-01,  1.1867e-04, -3.7021e-01,\n",
      "          1.2490e-01, -2.9751e-01, -1.7050e-01,  4.7761e-01, -3.3411e-01,\n",
      "          3.0790e-01, -4.1176e-01,  4.8420e-02, -2.9012e-01, -8.5755e-02,\n",
      "          6.3841e-02,  2.6675e-01,  3.9875e-01, -7.7334e-02,  3.5639e-01],\n",
      "        [ 1.9742e-01, -1.2683e-01,  4.4897e-01, -6.8639e-02,  2.6365e-01,\n",
      "         -3.4314e-01,  2.0939e-01,  2.4883e-01, -4.3736e-01,  1.1283e-01,\n",
      "          1.2065e-01,  6.1833e-02, -7.4991e-02,  4.4509e-01,  4.8039e-01,\n",
      "         -2.2098e-01, -2.0250e-01,  8.9957e-02,  6.8241e-02, -2.8958e-01],\n",
      "        [ 1.1554e-01,  2.5407e-01, -3.6686e-01, -7.0061e-03, -3.1652e-01,\n",
      "          1.1438e-01, -4.3263e-02, -2.1105e-01, -3.1428e-01, -3.9464e-01,\n",
      "          1.1047e-01,  1.3897e-01,  1.7022e-01, -1.6156e-01,  5.8096e-02,\n",
      "          2.0186e-01, -3.1770e-01,  2.8833e-01,  3.5766e-01, -1.3952e-02],\n",
      "        [ 3.3889e-01,  1.3462e-01,  1.0647e-01, -4.3349e-01, -2.6660e-01,\n",
      "          1.9090e-01,  2.1399e-01,  3.8008e-01, -3.6730e-01,  4.1899e-01,\n",
      "          4.8721e-01,  1.3851e-01, -6.4515e-02,  4.7064e-01, -8.5011e-02,\n",
      "         -8.8936e-02, -1.3436e-01,  4.7570e-01,  4.8766e-01,  4.9413e-02]],\n",
      "       requires_grad=True)), ('fc.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "l = LSTM(5, 10, 20, 2, 0.2)\n",
    "u = l.init_hidden(50, \"cpu\")\n",
    "v = l.init_weights()\n",
    "\n",
    "u[0].size()\n",
    "print(list(l.named_parameters()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speakeeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
