{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next-word implementation in LSTM model\n",
    "\n",
    "Predict the next word in a sentence using LSTM models. Training data in `.txt` form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # text preprocessing\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  # pad sequences to the same length\n",
    "from tensorflow.keras.models import Sequential, load_model  # initialize a sequential model, load a model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense  # word embeddings, LSTMs, and fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/rishabh/code/eeg/SPEAK_EEG/DATA/non-eeg/sherlock-holmes.txt\"\n",
    "# DATA_PATH = \"nwtest.txt\"\n",
    "\n",
    "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as F:\n",
    "    text = F.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1676"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply tokenizer to preprocess dataset into individual tokens\n",
    "tk = Tokenizer()\n",
    "\n",
    "tk.fit_on_texts([text])\n",
    "\n",
    "total_words = len(tk.word_index) + 1\n",
    "\n",
    "total_words # 8200\n",
    "tk.word_index[\"test\"] # each word as a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1561],\n",
       " [1, 1561, 5],\n",
       " [1, 1561, 5, 129],\n",
       " [1, 1561, 5, 129, 34],\n",
       " [647, 4498],\n",
       " [647, 4498, 4499],\n",
       " [226, 5],\n",
       " [226, 5, 1562],\n",
       " [6, 827],\n",
       " [6, 827, 7],\n",
       " [6, 827, 7, 871],\n",
       " [1, 234],\n",
       " [1, 234, 462],\n",
       " [1, 234, 462, 648],\n",
       " [6, 110],\n",
       " [6, 110, 5],\n",
       " [6, 110, 5, 2072],\n",
       " [1, 678],\n",
       " [1, 678, 1360],\n",
       " [1, 678, 1360, 499]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N-gram implementation (identical to `nw.ipynb`)\n",
    "# https://devopedia.org/n-gram-model\n",
    "\n",
    "# declare N-grams\n",
    "input_sequences = []\n",
    "\n",
    "for line in text.split(\"\\n\"):\n",
    "    # get the tokened version of each line\n",
    "    tk_list = tk.texts_to_sequences([line])[0]\n",
    "\n",
    "    # add an N-gram of length >= 2 to list of all N-grams\n",
    "    for i in range(1, len(tk_list)):\n",
    "        N_sequence = tk_list[:i+1]\n",
    "        input_sequences.append(N_sequence)\n",
    "\n",
    "# we now have all non-uni N-grams\n",
    "input_sequences[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96314"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max sentence length\n",
    "max_sequence_len = max(map(len, input_sequences))\n",
    "\n",
    "# update input_sequences \n",
    "input_sequences_list = list(map(list, pad_sequences(input_sequences, maxlen=max_sequence_len, padding=\"pre\")))\n",
    "\n",
    "input_sequences_list[:7] # the sequence is left-padded ([0, 0, 0, 0, ..., 3, 4, 5])\n",
    "\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding=\"pre\"))\n",
    "\n",
    "len(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1561,    5,  129, ..., 8199, 3187, 3186], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]\n",
    "\n",
    "\"\"\"\n",
    "0 0 0 0 X X y\n",
    "0 0 0 X X X y\n",
    "0 0 X X X X y\n",
    "...\n",
    "\"\"\"\n",
    "y # the last word in every N-gram\n",
    "\n",
    "# now, we can essentially train our model to predict the next next word\n",
    "# given the sentence prior to it, for ALL sentence lengths.\n",
    "# this will allow our model to recognize words that are common\n",
    "# in the beginning of sentences, and words that immediately follow it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96314, 8200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding implementation\n",
    "y = np.array(tf.keras.utils.to_categorical(y, num_classes=total_words))\n",
    "\n",
    "y.shape # (num of N-gram lines, num of unique words) = (96314, 8200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "Uncomment for retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # linear stack of layers type model\n",
    "# model = Sequential()\n",
    "\n",
    "# # embed - transforms input array into dense vectors\n",
    "# model.add(Embedding(total_words, 100, input_length=max_sequence_len - 1))\n",
    "# \"\"\"\n",
    "# total_words : total words in vocabulary (8200)\n",
    "# 100 : dimension of the dense embedding; each word is mapped to a 100-dimensional vector\n",
    "# input_length : length of input sequences\n",
    "# \"\"\"\n",
    "\n",
    "# model.add(LSTM(150)) # 150 nodes in the LSTM layer\n",
    "\n",
    "# model.add(Dense(total_words, activation=\"softmax\")) # output layer of length `total_words`\n",
    "\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# model.fit(X, y, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"NW.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"NW.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'about', 'is', 'might', 'of', 'that', 'to', 'was', 'we', 'who', 'you'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text = \"his name\"\n",
    "top_k = 10\n",
    "seed_out = set()\n",
    "\n",
    "tk_list = tk.texts_to_sequences([seed_text])[0]\n",
    "\n",
    "tk_list = pad_sequences([tk_list], maxlen=max_sequence_len - 1, padding=\"pre\")\n",
    "\n",
    "# predicted = np.argmax(model.predict(tk_list), axis=-1) # gets top word\n",
    "\n",
    "# get a list of the top_k argmaxes\n",
    "predicted = np.argsort(model.predict(tk_list), axis=-1)[:,-top_k:]\n",
    "\n",
    "for word, index in tk.word_index.items():\n",
    "    if index in predicted:\n",
    "        seed_out.add(word)\n",
    "\n",
    "seed_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'his name is francis prosper and yet what came'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text = \"his name\"\n",
    "next_words = 7\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tk.texts_to_sequences([seed_text])[0]\n",
    "\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding=\"pre\")\n",
    "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "    output_word = \"\"\n",
    "\n",
    "    for word, index in tk.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "\n",
    "seed_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speakeeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
