{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual P300 Notebook\n",
    "\n",
    "Referencing [NeurotechX EEG notebook](https://neurotechx.github.io/EEG-ExPy/experiments/vp300.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## P300 Load and visualize data\n",
    "\n",
    "We employ our own `preprocess.py` file to visualize data components. We also use `classify-#.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from collections import OrderedDict # to organize various models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# MNE-python\n",
    "from mne import Epochs, find_events\n",
    "\n",
    "# EEG-notebooks implementations\n",
    "    # implemented: load_data, _get_recording_dir\n",
    "    # todo: load_subjects\n",
    "from pathlib import Path\n",
    "from os import path, makedirs\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/rishabh/code/eeg/speakEEG/data_master/neurosity/visual-p300/2024_10_21_session01')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = path.join(path.expanduser(\"~\"), \"code\", \"eeg\", \"speakEEG\", \"data_master\")\n",
    "\n",
    "def my_recording_file(\n",
    "    device_name: str, # 'neurosity'\n",
    "    experiment: str, # 'visual-p300'\n",
    "    session_id: int = -1, # unprovided session_id will be automatically assigned\n",
    "    data_dir: str = DATA_DIR\n",
    ") -> Path:\n",
    "\n",
    "    # session id assignment\n",
    "    if session_id == -1:\n",
    "        session_id = 1\n",
    "        while path.exists(Path(data_dir) / device_name / experiment / f\"{datetime.today().strftime('%Y_%m_%d')}_session{str(session_id).zfill(2)}\"):\n",
    "            session_id += 1\n",
    "\n",
    "    session_id = str(session_id).zfill(2)\n",
    "    session_id = f\"{datetime.today().strftime('%Y_%m_%d')}_session{session_id}\"\n",
    "    recording_dir = Path(data_dir) / device_name / experiment / session_id  # e.g. 'neurosity/visual-p300/2021-09-01_session01'\n",
    "\n",
    "    if not path.exists(recording_dir):\n",
    "        makedirs(recording_dir)\n",
    "    \n",
    "    return recording_dir\n",
    "\n",
    "my_recording_file('neurosity', 'visual-p300')#, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import moabb\n",
    "from moabb.datasets import BNCI2014_001, utils\n",
    "from moabb.evaluations import CrossSessionEvaluation\n",
    "from moabb.paradigms import LeftRightImagery\n",
    "from moabb.pipelines.features import LogVariance\n",
    "\n",
    "moabb.set_log_level(\"info\")\n",
    "\n",
    "pipelines = {}\n",
    "pipelines[\"AM+LDA\"] = make_pipeline(LogVariance(), LDA())\n",
    "parameters = {\"C\": np.logspace(-2, 2, 10)}\n",
    "clf = GridSearchCV(SVC(kernel=\"linear\"), parameters)\n",
    "pipe = make_pipeline(LogVariance(), clf)\n",
    "\n",
    "pipelines[\"AM+SVM\"] = pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<moabb.datasets.bnci.BNCI2014_001 at 0x10f5a82d0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = BNCI2014_001()\n",
    "dataset.subject_list = dataset.subject_list[:2]\n",
    "datasets = [dataset]\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmin = 8\n",
    "fmax = 35\n",
    "paradigm = LeftRightImagery(fmin=fmin, fmax=fmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 06:13:46,568 INFO MainThread moabb.evaluations.base Processing dataset: BNCI2014-001\n",
      "BNCI2014-001-CrossSession:   0%|          | 0/2 [00:00<?, ?it/s]Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A01T.mat' to file '/Users/rishabh/code/eeg/speakEEG/data/MNE-bnci-data/database/data-sets/001-2014/A01T.mat'.\n",
      "100%|█████████████████████████████████████| 42.8M/42.8M [00:00<00:00, 16.0GB/s]\n",
      "SHA256 hash of downloaded file: 054f02e70cf9c4ada1517e9b9864f45407939c1062c6793516585c6f511d0325\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A01E.mat' to file '/Users/rishabh/code/eeg/speakEEG/data/MNE-bnci-data/database/data-sets/001-2014/A01E.mat'.\n",
      "100%|█████████████████████████████████████| 43.8M/43.8M [00:00<00:00, 12.1GB/s]\n",
      "SHA256 hash of downloaded file: 53d415f39c3d7b0c88b894d7b08d99bcdfe855ede63831d3691af1a45607fb62\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "2024-10-21 06:14:05,174 INFO MainThread moabb.evaluations.base AM+LDA | BNCI2014-001 | 1 | 0train: Score 0.786\n",
      "2024-10-21 06:14:05,520 INFO MainThread moabb.evaluations.base AM+LDA | BNCI2014-001 | 1 | 1test: Score 0.802\n",
      "2024-10-21 06:14:06,038 INFO MainThread moabb.evaluations.base AM+SVM | BNCI2014-001 | 1 | 0train: Score 0.797\n",
      "2024-10-21 06:14:06,582 INFO MainThread moabb.evaluations.base AM+SVM | BNCI2014-001 | 1 | 1test: Score 0.774\n",
      "BNCI2014-001-CrossSession:  50%|█████     | 1/2 [00:20<00:20, 20.13s/it]Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A02T.mat' to file '/Users/rishabh/code/eeg/speakEEG/data/MNE-bnci-data/database/data-sets/001-2014/A02T.mat'.\n",
      "100%|█████████████████████████████████████| 43.1M/43.1M [00:00<00:00, 23.7GB/s]\n",
      "SHA256 hash of downloaded file: 5ddd5cb520b1692c3ba1363f48d98f58f0e46f3699ee50d749947950fc39db27\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A02E.mat' to file '/Users/rishabh/code/eeg/speakEEG/data/MNE-bnci-data/database/data-sets/001-2014/A02E.mat'.\n",
      "100%|█████████████████████████████████████| 44.2M/44.2M [00:00<00:00, 13.8GB/s]\n",
      "SHA256 hash of downloaded file: d63c454005d3a9b41d8440629482e855afc823339bdd0b5721842a7ee9cc7b12\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "2024-10-21 06:14:23,309 INFO MainThread moabb.evaluations.base AM+LDA | BNCI2014-001 | 2 | 0train: Score 0.577\n",
      "2024-10-21 06:14:23,649 INFO MainThread moabb.evaluations.base AM+LDA | BNCI2014-001 | 2 | 1test: Score 0.499\n",
      "2024-10-21 06:14:24,313 INFO MainThread moabb.evaluations.base AM+SVM | BNCI2014-001 | 2 | 0train: Score 0.551\n",
      "2024-10-21 06:14:24,875 INFO MainThread moabb.evaluations.base AM+SVM | BNCI2014-001 | 2 | 1test: Score 0.471\n",
      "BNCI2014-001-CrossSession: 100%|██████████| 2/2 [00:38<00:00, 19.21s/it]\n"
     ]
    }
   ],
   "source": [
    "evaluation = CrossSessionEvaluation(\n",
    "    paradigm=paradigm, datasets=datasets, suffix=\"examples\", overwrite=False\n",
    ")\n",
    "results = evaluation.process(pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score      time  samples subject session  channels  n_sessions  \\\n",
      "0  0.797068  0.283806    144.0       1  0train        22           2   \n",
      "1  0.773920  0.289637    144.0       1   1test        22           2   \n",
      "2  0.550733  0.429853    144.0       2  0train        22           2   \n",
      "3  0.471451  0.305453    144.0       2   1test        22           2   \n",
      "4  0.786458  0.156156    144.0       1  0train        22           2   \n",
      "\n",
      "        dataset pipeline  \n",
      "0  BNCI2014-001   AM+SVM  \n",
      "1  BNCI2014-001   AM+SVM  \n",
      "2  BNCI2014-001   AM+SVM  \n",
      "3  BNCI2014-001   AM+SVM  \n",
      "4  BNCI2014-001   AM+LDA  \n"
     ]
    }
   ],
   "source": [
    "print(results.head()) # pd dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
